)
mvrnorm(n=1,c(1,2),S)
mvrnorm(n=1,c(1,2),S)
mvrnorm(n=1,c(1,2),S)
mvrnorm(n=1,c(1,2),S)
a <- list(a=7,b="privet",S)
a
a[[2]]
a[[3]]
a[3]
a[[3]]
a[3]
str(a[[3]])
str(a[3])
library(stats)
rWishart(n=1,9,S)
rWishart(n=1,9,S)
rWishart(n=1,9,S)
data()
"CoalDisast" <-
structure(list(Year = as.integer(c(1851, 1852, 1853, 1854, 1855,
1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866,
1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877,
1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888,
1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899,
1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910,
1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921,
1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932,
1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943,
1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954,
1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962)), Count = c(4,
5, 4, 1, 0, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3,
1, 4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1,
1, 1, 3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,
0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 1, 2,
1, 1, 1, 1, 2, 4, 2, 0, 0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0,
1, 0, 0, 1, 0, 1)), .Names = c("Year", "Count"), row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
"14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
"25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
"36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
"47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",
"58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",
"69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",
"80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",
"91", "92", "93", "94", "95", "96", "97", "98", "99", "100",
"101", "102", "103", "104", "105", "106", "107", "108", "109",
"110", "111", "112"), class = "data.frame")
str(CoalDisast)
library(plm)
library(plm)
EmplUK <- plm.data(EmplUK, index = c("firm", "year"))
data("EmplUK", package = "plm")
EmplUK <- plm.data(EmplUK, index = c("firm", "year"))
data("Grunfeld", package = "Ecdat")
data("Grunfeld", package = "Ecdat")
grun.re <- plm(inv ~ value + capital, data = Grunfeld, model = "random")
summary(grun.re)
residuals(grun.re)
fixef(grun.re)
summary(Grunfeld)
a<-residuals(grun.re)
str(a)
Grunfeld$a <- a
as.vector(a)
Grunfeld$a <- residuals(grun.re)
Grunfeld$res <- residuals(grun.re)
450/545
a=seq(from=364,to=336,by=-1)
a
prod()
prod(a)
prod(a)/365^29
vif
?vif
??vif
library(car)
a <- cars
m <- lm(dist~speed,data=cars)
vif(m)
m <- lm(dist~speed+I(speed^3),data=cars)
vif(m)
library(MASS)
m.rr <- lm.ridge(dist~speed+I(speed^3),data=cars,lambda=c(0.1,0.5,0.9))
summary(m.rr)
m.rr$coef
library(lars)
library(lars)
?model.matrix
library(glmnet)
h <- cars
X <- model.matrix(~speed+I(speed^3),data=cars)
y <- h$dist
fit <- glmnet(X,y)
plot(fit)
cvfit <- cv.glmnet(X,y)
plot(cvfit)
coef(fit,s=cvfit$lambda.min)
coef(fit)
head(X)
X <- model.matrix(~0+speed+I(speed^3),data=cars)
y <- h$dist
fit <- glmnet(X,y)
plot(fit)
cvfit <- cv.glmnet(X,y)
plot(cvfit)
coef(fit,s=cvfit$lambda.min)
coef(fit)
fit$lambda
fit$beta
fit$beta
fit$a0
cvfit
cvfit <- cv.glmnet(X,y)
plot(cvfit)
plot(fit)
р
h
plot(h)
h <- cars
m2 <- lm(dist~speed^3,data=h)
summary(m2)
m2 <- lm(dist~speed+I(speed^3),data=h)
summary(m2)
vcov(m2)
nrow(h)
new <- data.frame(speed=10)
predict(m2,newdata=new)
new
z <- c(1,10,100)
z <- c(1,10,1000)
z
t(z) %*% vcov(m2) %*% z
z %*% vcov(m2) %*% t(z)
z %*% vcov(m2) %*% z
t(z) %*% vcov(m2) %*% z
nrow(h)
qt(p=0.95,df=47)
?predict
predict(m2,new,se=TRUE)
predict(m2,new,se=TRUE,prediction.interval=TRUE)
predict(m2,new,se=TRUE)
prediction <- predict(m2,new,se=TRUE)
ci.left <- prediction$fit-qt(0.95,47)*prediction$se.fit
ci.ri <- prediction$fit+qt(0.95,47)*prediction$se.fit
ci.left
ci.ri
h$cens <- speed-mean(speed)
h$cens <- speed-mean(h$speed)
h
head(h)
h$cens <- h$speed-mean(h$speed)
m3 <- lm(dist~cens+I(cens^3),data=h)
summary(m3)
m4 <- lm(dist~speed+I(speed^2)+I(speed^3),data=h)
m5 <- lm(dist~cens+I(cens^2)+I(cens^3),data=h)
summary(m4)
summary(m5)
new
new$cens <- 10-mean(h$speed)
new
plot(cars)
plot(cars)
predict(m4,new,se=TRUE)
predict(m5,new,se=TRUE)
library(MASS)
m6 <- lm.ridge(dist~speed+I(speed^2)+I(speed^3),data=h,lambda=seq(from=0.1,to=10,by=0.1))
?cars
summary(m6)
coef(m6)
plot(coef(m6))
plot(m6)
select(m6)
add.m <- lm(speed~I(speed^2)+I(speed^3),data=h)
summary(add.m)$r.squared
1/(1-summary(add.m)$r.squared)
library(cars)
library(car)
m3
m2
m4
library(car)
vif(m4)
X <- model.matrix(~speed+I(speed^2)+I(speed^3),data=h)
head(X)
t(X) %*% X
XX <- t(X) %*% X
eigen(XX)
eigen(XX)$values
max(eigen(XX)$values)
min(eigen(XX)$values)
sqrt(max(eigen(XX)$values)/min(eigen(XX)$values))
d <- data.frame(x=rnorm(100),y=rnorm(100),z=rnorm(100),w=rnorm(100))
lm(y~x+x^3,d)
lm(y~x+(x+z)^2,d)
lm(y~(x+z)^2,d)
lm(y~(x+z)^3,d)
lm(y~(x+z+w)^2,d)
lm(y~(x+z+w)^3,d)
library(knitr)
opts_chunk$set(cache=TRUE)
library(ggplot2) # графики
library(glmnet) # LASSO
library(MASS) # ridge regression
library(car) # compute vif()
# install.packages("glmnet") # может быть нужно установить пакеты...
h <- cars
plot(h)
m.poly3 <- lm(dist~speed+I(speed^2)+I(speed^3),data=h)
summary(m.poly3)
vcov(m.poly3)
lambdas <- seq(0.1,10,by=0.1) # для этих лямбд будем делать RR
m <- lm.ridge(dist~speed+I(speed^2)+I(speed^3),data=h)
summary(m)
head(m)
coef(m)
m <- lm.ridge(dist~speed+I(speed^2)+I(speed^3),lambda=lambdas,data=h)
coef(m)
head(coef(m.rr))
plot(m.rr)
m.rr <- lm.ridge(dist~speed+I(speed^2)+I(speed^3),lambda=lambdas,data=h)
coef(m.rr)
select(m.rr)
?predict
new <- data.frame(speed=10)
predict(m.poly3,newdata=new,interval='confidence',se.fit=TRUE)
h$spc <- h$speed - mean(h$speed)
m.poly3c <- lm(dist~spc+I(spc^2)+I(spc^3),data=h)
summary(m.poly3c)
h$spc <- h$speed - mean(h$speed)
m.poly3c <- lm(dist~spc+I(spc^2)+I(spc^3),data=h)
summary(m.poly3c)
vcov(m.poly3c)
new$spc <- 10 - mean(h$speed)
predict(m.poly3c,newdata=new,interval='confidence')
predict(m.poly3,newdata=new,interval='confidence')
X <- model.matrix(~0+speed+I(speed^2)+I(speed^3),data=cars)
y <- h$dist
fit <- glmnet(X,y)
plot(fit)
cvfit <- cv.glmnet(X,y)
plot(cvfit)
coef(fit,s=cvfit$lambda.min)
coef(fit)
head(coef(fit))
str(coef(fit))
coef(fit)[,1:5]
fit$a0
fit$beta
str(fit$beta)
str(fit$a0)
fit$lambda
select(fit)
cvfit <- cv.glmnet(X,y)
summary(cvfit)
cvfit$lambda.min
cvfit$lambda
X <- model.matrix(~speed+I(speed^2)+I(speed^3),data=h)
XX <- t(X) %*% X
eigens <- eigen(XX)
eigens$values
eigen$values
eigen <- eigen(XX)
eigen$values
CI <- sqrt(max(eigen$values)/min(eigen$values))
CI
?cor
X <- model.matrix(~0+speed+I(speed^2)+I(speed^3),data=h)
cor(X)
vif(m.poly3)
r2.1 <- summary(m.vif1)$r.squared
m.vif1 <- lm(speed~I(speed^2)+I(speed^3),data=h)
r2.1 <- summary(m.vif1)$r.squared
vif1 <- 1/(1-r2.1)
vif1
library(knitr)
opts_chunk$set(cache=TRUE)
library(ggplot2) # графики
library(glmnet) # LASSO
library(MASS) # ridge regression
library(car) # compute vif()
# install.packages("glmnet") # может быть нужно установить пакеты...
h <- cars
plot(h)
m.poly3 <- lm(dist~speed+I(speed^2)+I(speed^3),data=h)
summary(m.poly3)
X <- model.matrix(~0+speed+I(speed^2)+I(speed^3),data=h)
cor(X)
X <- model.matrix(~speed+I(speed^2)+I(speed^3),data=h)
XX <- t(X) %*% X
eigen <- eigen(XX)
eigen$values
CI <- sqrt(max(eigen$values)/min(eigen$values))
CI
vif(m.poly3)
m.vif1 <- lm(speed~I(speed^2)+I(speed^3),data=h)
r2.1 <- summary(m.vif1)$r.squared
vif1 <- 1/(1-r2.1)
vif1
vcov(m.poly3)
new <- data.frame(speed=10)
predict(m.poly3,newdata=new,interval='confidence')
h$spc <- h$speed - mean(h$speed)
m.poly3c <- lm(dist~spc+I(spc^2)+I(spc^3),data=h)
summary(m.poly3c)
vcov(m.poly3c)
new$spc <- 10 - mean(h$speed)
predict(m.poly3c,newdata=new,interval='confidence')
m.line <- lm(dist~speed,data=h)
summary(m.line)
lambdas <- seq(0.1,10,by=0.1) # для этих лямбд будем делать RR
m.rr <- lm.ridge(dist~speed+I(speed^2)+I(speed^3),lambda=lambdas,data=h)
head(coef(m.rr))
plot(m.rr)
m.rr
select(m.rr)
select(m.rr)
?select
?expand.grid
expand.grid(1:4,1:13)
h<-expand.grid(1:4,1:13)
sample(h,5)
sample(t(h),5)
sample(1:36,36)
sample(1:36,36)
sample(1:36,36)
sample(1:36,36)
sample(1:36,36)
sample(1:36,36)
sample(1:36,36)
?read.table
?set.seed
set.seed(3.5)
x <- rnorm(100)
x
x <- rnorm(10)
x
?rpois
y <- rpois(10000000,lambda=5)
mean(y)
?mean
sd(y)
var(y)
sd(y)^2
z <- x^3
X
X <- 5
X
x
z <- y^3
mean(z)
mean(y^3)
var(y^2+y^3)
tf <- y^2>y+100
tf.liza <- y^2>y+100
tf.liza[1:20]
sum(tf.liza)
sum(tf.liza)/1000000
n <- 10^6
y <- rpois(n,lambda=5)
tf.liza <- y^2>y+100
tf.liza[1:20]
sum(tf.liza)
# ответ на P(X^2>X+100)
sum(tf.liza)/n
setwd('~/science/probability/pr201/training_koko/koko/')
dir()
####
x <- rnorm(10)
x
?rpois
### задача 1
n <- 10^6
y <- rpois(n,lambda=5)
mean(y) # среднее арифметические
?mean
sd(y) # выборочное ст. отклонение
var(y) # выборочная дисперсия
sd(y)^2
z <- y^3
mean(z)
mean(y^3) # примерный ответ на E(Y^3)
# примерный ответ на Var(X^2+X^3)
var(y^2+y^3)
tf.liza <- y^2>y+100
tf.liza[1:20]
sum(tf.liza)
# ответ на P(X^2>X+100)
sum(tf.liza)/n
### задача 3а
setwd('~/science/probability/pr201/training_koko/koko/')
dir()
h <- read.table("flats_moscow.txt",header=TRUE)
h
str(h)
h$price[1:10]
mean(h$price)
sd(h$price)
nrow(h)
z.crit <- qnorm(0.975)
z.crit
m.price <- mean(h$price)
sd.price <- sd(h$price)
ci.left <- m.price-z.crit*sd.price
ci.left <- m.price-z.crit*sd.price
ci.right <- m.price+z.crit*sd.price
ci.left
ci.right
set.seed(42)
x <- rexp(200)
x[1:10]
sq <- function(x) {
return(x^2)
}
sq(5)
log_lik <- function(a,x) {
n <- length(x)
res <- n*log(a)+(a-1)*sum(x)
return(-res)
}
log_lik(2,x)
log_lik(2,x)
log_lik(3,x)
?nlm # минимизация
opt <- nlm(log_lik,a=3,hessian=TRUE,x=x)
opt <- nlm(log_lik,p=3,hessian=TRUE,x=x)
opt
opt$estimate
opt$hessian
a.hat <- opt$hessian
a.var <- 1/opt$hessian
a.hat
a.hat <- opt$estimate
a.hat
a.var
h <- dir()
h
x <- rnorm(20)
x
?rpois
x <- rpois(n,lambda=5)
x <- rpois(n,lambda=5)
x[1:5]
mean(x) # среднее выборочное
var(x)
sd(x)
sd(x)^2
mean(x^3)
var(x^2+x^3)
x[1:10]
z <- x^2>x+100
z[1:5]
sum(z)
sum(z)/n
?rf
setwd("~/science/probability/pr201/training_koko/koko/")
dir()
?read.table
h <- read.table(
"flats_moscow.txt",
header=TRUE)
str(h) # инфо об h
h$price[1:5]
pr <- h$price
mean(h$price)
sd(h$price)
z.cr <- qnorm(0.975)
z.cr
ci.left <- mean(h$price)
- z.cr*sd(h$price)
ci.left <- mean(h$price)-z.cr*sd(h$price)
ci.right <- mean(h$price)+z.cr*sd(h$price)
ci.left <- mean(h$price)-z.cr*sd(h$price)
ci.right <- mean(h$price)+z.cr*sd(h$price)
ci.left
ci.right
set.seed(42)
x <- rexp(200)
x[1:5]
?set.seed()
ksusha <- function(x) {
return(x^2)
}
ksusha(7)
ksusha(pi)
log_lik <- function(a,dat) {
n <- length(dat)
res <- n*log(a) + (a-1)*sum(dat)
return(-res)
}
log_lik(2,x)
log_lik(5,x)
?nlm
opt <- nlm(log_lik,p=5,hessian=TRUE)
opt <- nlm(log_lik,p=5,
hessian=TRUE,dat=x)
opt$estimate
a.hat <- opt$estimate
a.hat
var.hat <- 1/opt$hessian
var.hat
300/18
sqrt(300/18)
20/sqrt(300/18)
1-pnorm(4.9)
pnorm(56)
pnorm(10)
pnorm(7)
pnorm(6)
2/3
1/18/150
sqrt(18*150)/9
