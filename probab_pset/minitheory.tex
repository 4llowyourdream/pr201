% minitheory

$\displaystyle \Omega $  = множество всех исходов

событие = набор исходов

свойства вероятности:  \\
$P(\Omega)=1$, $P(\emptyset)=0$,  $0\le P(C)\le 1$ \\
Если  $A$  и  $B$  несовместны (не могут произойти одновременно,
$A\cap B=\emptyset $ ), то  $P(A\cup B)=P(A)+P(B)$. \\

Существуют такое событие $D$, что $P(D)=0$, но $P\ne\emptyset$. \\

Число способов выбрать  $k$  предметов из $n$ ($C$ из  $n$  по
$k$), если не важен порядок: $C_{n}^{k} = (
\begin{array}{c}
  n \\
  k \\
\end{array}
) =\frac{n!}{k!(n-k)!}$. Maple: binomial(n,k); n!; \\


Условная вероятность наступления события  $A$, если известно, что
$B$ наступило =  $P(A|B)=\frac{P(A\cap B)}{P(B)} $ \\
условная вероятность определена при  $P(B)>0$ \\

события  $A$  и  $B$  называются независимыми, если  $P(A\cap
B)=P(A)\cdot P(B)$ или (для $P(B)>0$) $P(A|B)=P(A)$ \\


$A^{c} =\Omega \backslash A$  - дополнение к событию  $A$ \\

формула полной вероятности  $P(A)=P(A|B_{1} )\cdot P(B_{1}
)+...+P(A|B_{n} )\cdot P(B_{n} )$, если $B_{n} $  - не
пересекаются, и в сумме исчерпывают все возможные варианты. \\

Функция распределения  $F(a)=P(X\le a)$. \\

Функция  $p(t)$  называется функцией плотности для случайной
величины  $X$, если  $P(a\le X\le b)=\int _{a}^{b}p(t)dt $.
Функция плотности - это не вероятность. Это - почти :)
вероятность. \\

Для случайных величин с функцией плотности  $P(X=t)=0$. \\
Для всех $P(-\infty <X<+\infty )=1$. \\

Условная функция плотности  $p_{X|Y} (x|y)=\frac{p_{X,Y}
(x,y)}{p_{Y} (y)} $ \\
Для непрерывных с.в.  $F(a)=\int _{-\infty }^{a}p(t)dt $. \\


Для дискретных величин  $E(X)=\sum x_{i} \cdot P(X=x_{i} ) $,\\
Для непрерывных - $E(X)=\int x\cdot p(x)\cdot dx $. \\

Условное ожидание: \\
$E(X|A)=\sum x_{i} \cdot P(X=x_{i} |A) $.

Для удобства  $E(f(X))=\sum f(x_{i} )\cdot P(X=x_{i} ) $. \\


$E(aX+Y)=aE(X)+E(Y)$. \\


Дисперсия $Var(X)=E((X-E(X))^{2} )$. \\
Ковариация $Cov(X,Y)=E((X-E(X))(Y-E(Y)))$. \\
Cтандартное отклонение $\sigma _{X} =\sqrt{Var(X)} $ \\
Корреляция $cor(X,Y)=\frac{Cov(X,Y)}{\sigma _{X} \cdot \sigma
_{Y}}$ \\


С.в. независимы, если никакая информация о  $X$  не позволяет
сделать никаких выводов о  $Y$.

Для независимых с.в. $E(XY)=E(X)E(Y)$. Для дискретных независимых
случайных величин  $P(X=x\cap Y=y)=P(X=x)P(Y=y)$, для непрерывных
независимых $p_{X,Y} (x,y)=p_{X} (x)p_{Y} (y)$.

Выборочное среднее  $\bar{X}=\frac{X_{1} +...+X_{n} }{n} $, \\
Несмещенная оценка дисперсии  $\hat{\sigma }^{2} =\frac{\sum
(X_{i} -\bar{X})^{2}  }{n-1} $ \\

Центральная предельная теорема: \\
Если  $X_{i} $  - iid, $0<Var(X_{i} )<\infty $, то $\frac{S_{n}
-E(S_{n} )}{\sqrt{Var(S_{n} )} } \xrightarrow[{n\to \infty
}]{distribution} N(0;1)$. \\
Пуассоновское приближение: \\
Если  $L_{n} $  - биномиальные с.в. с параметрами  $(n,p_{n} )$  и
$np_{n} \stackrel{n\to \infty }{\longrightarrow}\lambda $, то
$P(L_{n} =k)\to e^{-\lambda } {\lambda ^{k} \mathord{\left/
{\vphantom {\lambda ^{k}  k!}} \right. \kern-\nulldelimiterspace}
k!} $ \\





Зоопарк:  \\
$p(t)=\lambda e^{-\lambda t}$, Экспоненциальное, $E(X)=\frac{1}{\lambda } $,  $Var(X)=\frac{1}{\lambda ^{2} } $ \\
$p(t)=\frac{1}{\sqrt{2\pi } \sigma } \exp (-\frac{(t-\mu )^{2}
}{2\sigma ^{2} } )$,
Нормальное \\
 $P(X=t)=e^{-\lambda } \frac{\lambda ^{t}
}{t!} $, Пуассон, $E(X)=\lambda $,  $Var(X)=\lambda $ \\
$P(X=t)=C_{N}^{t} p^{t} (1-p)^{N-t} $,
Биномиальное \\
$p(\vec{x}^{T} )=c \exp (-\frac{1}{2} (x-\mu )^{T} \Omega
^{-1} (x-\mu ))$, Многомерное нормальное \\

$X\sim N(\vec{\mu };\Omega )$,  $\Omega $ - ковариационная
матрица, $c=\frac{1}{(2\pi )^{{\tfrac{n}{2}} } \det
^{{\tfrac{1}{2}} } (\Omega
)}$ \\
Для двумерного нормального: \\
$E(X_{1}|X_{2})=\mu_{1}+\rho\frac{\sigma_{1}}{\sigma_{2}}(X_{2}-\mu_{2})$ \\
$Var(X_{1}|X_{2})=\sigma_{1}^{2}(1-\rho^{2})$ \\


События представляют собой Пуассоновский поток с параметром
$\lambda $: \\
Количество событий, происходящих за время  $t$  - с.в. имеющая
распределение Пуассона с ожиданием  $(\lambda \cdot
t)$.\\
Время между двумя событиями в потоке распределено экспоненциально
с ожиданием  $\frac{1}{\lambda } $.\\

Уровень значимости = <<порог редкости>>. Если происходит редкое
событие, то  $H_{0} $  отвергается.\\

Метод максимального правдоподобия:  Maximum likelihood, ML. \\
$\mathop{\max }\limits_{\theta } \prod p(x_{i},\theta
) $ \\
Полезен переход к логарифму. \\


Метод моментов: Method of moments, MM. \\
Если $E(\bar{X})=f(\theta)$, то находим  $\hat{\theta }$  из
уравнения $\bar{X}=f(\hat{\theta})$. \\


Оценка $\hat{\theta}$ неизвестного параметра $\theta$ называется: \\
несмещенной, если  $E(\hat{\theta})=\theta$ \\
состоятельной, если для  $\forall \varepsilon
>0$   $\lim P(|\theta -\hat{\theta }_{n}|>\varepsilon )=0$. \\
эффективной среди некоторого набора оценок, если
у нее минимальная дисперсия. \\

MSE, mean squared error,
$MSE(\hat{\theta})=E((\hat{\theta}-\theta)^{2})$ \\


If $X_{i}$ - iid, $N(\mu,\sigma^{2})$, then
$\frac{(n-1)\cdot\hat{\sigma}^{2}}{\sigma^{2}}=
\frac{\sum (X_{i}-\overline{X})^{2}}{\sigma^{2}}$ - $\chi_{(n-1)}$. \\

$\sum \frac{(X_{i}-n p_{i})^{2}}{n p_{i}}\sim \chi_{r-1}^{2}$;
$\sum \frac{(X_{i,j}-n \hat{p}_{i,j})^{2}}{n\hat{p}_{i,j}}\sim
\chi_{(r-1)(c-1)}^{2}$. If $X\sim N(0;1)$ and $K\sim \chi_{n}^{2}$
then $Y=\frac{X}{\sqrt{\frac{K}{n}}}$ is called $t_{n}$.  If
$X_{i}$ - iid $N(\mu,\sigma^2)$, then
$\frac{X_{n}-\mu}{\sqrt{\frac{\hat{\sigma}^2}{n}}}\sim t_{n-1}$. \\
